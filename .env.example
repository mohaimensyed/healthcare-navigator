# Healthcare Cost Navigator - Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL Database URL (recommended for production)
# Format: postgresql+asyncpg://username:password@host:port/database_name
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/healthcare

# For Docker Compose (use this when running with docker-compose)
# DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/healthcare

# Alternative: SQLite for development/testing (not recommended for production)
# DATABASE_URL=sqlite+aiosqlite:///./healthcare.db

# =============================================================================
# OPENAI CONFIGURATION (REQUIRED)
# =============================================================================

# Your OpenAI API key - get this from https://platform.openai.com/api-keys
# This is REQUIRED for the AI assistant functionality
OPENAI_API_KEY=your_openai_api_key_here

# Optional: OpenAI organization ID (if you're part of an organization)
# OPENAI_ORG_ID=your_org_id_here

# =============================================================================
# POSTGRESQL CONFIGURATION (for Docker)
# =============================================================================

# These are used by Docker Compose to set up the PostgreSQL container
POSTGRES_DB=healthcare
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Application environment (development, staging, production)
ENVIRONMENT=development

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Enable debug mode (shows more detailed error messages)
DEBUG=true

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# EXTERNAL SERVICES (Optional)
# =============================================================================

# If you want to use real geocoding instead of approximations
# Get a free key from https://geocoder.readthedocs.io/
# GEOCODING_API_KEY=your_geocoding_api_key_here

# For enhanced error tracking (optional)
# SENTRY_DSN=your_sentry_dsn_here

# =============================================================================
# PERFORMANCE TUNING (Advanced)
# =============================================================================

# Database connection pool settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600

# API rate limiting (requests per minute per IP)
RATE_LIMIT_RPM=60

# Maximum number of results to return from searches
MAX_SEARCH_RESULTS=100

# Cache TTL in seconds (if using Redis cache)
CACHE_TTL=3600

# =============================================================================
# SECURITY (Production)
# =============================================================================

# Secret key for session management (generate a random string for production)
# SECRET_KEY=your_very_secure_secret_key_here

# CORS allowed origins (comma-separated list)
# For development: http://localhost:3000,http://127.0.0.1:3000
# For production: https://your-domain.com
CORS_ORIGINS=*

# Enable HTTPS redirect in production
FORCE_HTTPS=false

# =============================================================================
# DATA CONFIGURATION
# =============================================================================

# Path to your CMS data file
DATA_FILE_PATH=data/sample_prices_ny.csv

# Batch size for ETL operations
ETL_BATCH_SIZE=1000

# Maximum file size for uploads (in MB)
MAX_FILE_SIZE_MB=100

# =============================================================================
# MONITORING & OBSERVABILITY (Optional)
# =============================================================================

# Enable metrics collection
ENABLE_METRICS=false

# Prometheus metrics endpoint
METRICS_ENDPOINT=/metrics

# Health check endpoint
HEALTH_CHECK_ENDPOINT=/health

# =============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT ENVIRONMENTS
# =============================================================================

# --- DEVELOPMENT ---
# Use SQLite for quick local development:
# DATABASE_URL=sqlite+aiosqlite:///./dev_healthcare.db
# DEBUG=true
# LOG_LEVEL=DEBUG

# --- TESTING ---
# Use in-memory SQLite for tests:
# DATABASE_URL=sqlite+aiosqlite:///:memory:
# ENVIRONMENT=testing

# --- PRODUCTION ---
# Use managed PostgreSQL service:
# DATABASE_URL=postgresql+asyncpg://user:password@your-db-host:5432/healthcare_prod
# DEBUG=false
# LOG_LEVEL=WARNING
# FORCE_HTTPS=true
# CORS_ORIGINS=https://your-production-domain.com

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================

# 1. Copy this file to .env:
#    cp .env.example .env

# 2. Edit .env and add your actual values, especially:
#    - OPENAI_API_KEY (required)
#    - DATABASE_URL (if not using Docker default)

# 3. If using Docker Compose:
#    docker-compose up -d

# 4. If running locally:
#    pip install -r requirements.txt
#    python app/init_db.py init
#    python etl.py
#    uvicorn app.main:app --reload

# =============================================================================
# TROUBLESHOOTING
# =============================================================================

# Common issues and solutions:

# 1. "OPENAI_API_KEY not found"
#    → Make sure you've set OPENAI_API_KEY in your .env file
#    → Get your API key from https://platform.openai.com/api-keys

# 2. Database connection errors:
#    → Check that PostgreSQL is running
#    → Verify DATABASE_URL format and credentials
#    → For Docker: make sure containers are up with `docker-compose ps`

# 3. "No module named 'app'" errors:
#    → Make sure you're running commands from the project root
#    → Check that __init__.py files exist in app/ and app/services/

# 4. ETL fails with "CSV file not found":
#    → Make sure your data file exists at the path specified in DATA_FILE_PATH
#    → Check file permissions

# 5. AI assistant returns errors:
#    → Verify OPENAI_API_KEY is correct
#    → Check OpenAI API quota/billing
#    → Ensure database has data (run ETL first)

# For more help, check the README.md file or the troubleshooting section.